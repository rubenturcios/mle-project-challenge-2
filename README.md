# House Price Prediction ML Application

[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)
[![MLflow](https://img.shields.io/badge/MLflow-tracking-blue.svg)](https://mlflow.org/)
[![Prefect](https://img.shields.io/badge/Prefect-orchestration-blue.svg)](https://www.prefect.io/)

> A production-ready machine learning application showcasing end-to-end ML engineering skills: from data exploration and model training with MLflow experiment tracking and Prefect workflow orchestration, to containerized deployment with Docker Swarm and Nginx load balancing.

## ğŸ¯ Project Overview

This project demonstrates a **complete production ML pipeline** for predicting house prices using the King County housing dataset. It showcases industry best practices in:

- **ML Engineering**: Feature engineering, model versioning, experiment tracking
- **Software Engineering**: Type-safe modular design, separation of concerns
- **DevOps/MLOps**: Containerization, orchestration, scalable deployment, load balancing

**Live Demo**: [Add your deployed link if available]

## âœ¨ Key Technical Highlights

### Machine Learning & MLOps
- âœ… **Prefect Orchestration**: Automated workflow management and scheduling
- âœ… **MLflow Integration**: Complete experiment tracking and model registry
- âœ… **Feature Engineering**: Demographic data enrichment for improved predictions
- âœ… **Model Versioning**: Serialized models with tracked feature schemas
- âœ… **Reproducibility**: Versioned experiments with artifact storage
- âœ… **Model Registry**: Production-ready model versioning and staging
- âœ… **Pipeline Automation**: Scheduled retraining and deployment workflows

### Production Engineering
- âœ… **Microservices Architecture**: Separate model and application services
- âœ… **Container Orchestration**: Docker Swarm for high availability
- âœ… **Load Balancing**: Nginx reverse proxy for traffic distribution
- âœ… **Horizontal Scaling**: Dynamic service scaling based on demand
- âœ… **Health Monitoring**: Service health checks and auto-recovery

### Software Engineering
- âœ… **Type Safety**: Custom type definitions and type hints throughout
- âœ… **Modular Design**: Clear separation of concerns (model, UI, utils, types)
- âœ… **Environment Management**: Both pip and conda specifications
- âœ… **Code Organization**: Clean project structure following best practices

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Client Layer                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Nginx Load Balancer                      â”‚
â”‚          (Port 80 - Traffic Distribution)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  App Service 1  â”‚           â”‚  App Service N  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚           â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  UI Layer â”‚  â”‚    ...    â”‚  â”‚  UI Layer â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚           â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â”‚        â”‚           â”‚        â”‚        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”‚           â”‚  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Model   â”‚  â”‚           â”‚  â”‚   Model   â”‚  â”‚
â”‚  â”‚  Service  â”‚  â”‚           â”‚  â”‚  Service  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚      Orchestration Layer       â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚   Prefect Workflows     â”‚  â”‚
        â”‚  â”‚  - Data Ingestion       â”‚  â”‚
        â”‚  â”‚  - Model Training       â”‚  â”‚
        â”‚  â”‚  - Model Deployment     â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â”‚              â”‚                 â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚     MLflow Server       â”‚  â”‚
        â”‚  â”‚   (Experiments &        â”‚  â”‚
        â”‚  â”‚    Model Registry)      â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Project Structure

```
.
â”œâ”€â”€ ğŸ“ data/                          # Dataset management
â”‚   â”œâ”€â”€ kc_house_data.csv            # Raw housing data
â”‚   â”œâ”€â”€ zipcode_demographics.csv     # Demographic enrichment
â”‚   â”œâ”€â”€ combined.csv                 # Processed training data
â”‚   â””â”€â”€ future_unseen_examples.csv   # Validation dataset
â”‚
â”œâ”€â”€ ğŸ“ model/                         # Model artifacts
â”‚   â”œâ”€â”€ create_model.py              # Training pipeline
â”‚   â”œâ”€â”€ evaluator.py                 # Model evaluation
â”‚   â”œâ”€â”€ model.pkl                    # Serialized model
â”‚   â””â”€â”€ model_features.json          # Feature schema
â”‚
â”œâ”€â”€ ğŸ“ src/                           # Application code
â”‚   â”œâ”€â”€ main.py                      # API entry point
â”‚   â”œâ”€â”€ ui.py                        # Web interface
â”‚   â”œâ”€â”€ model.py                     # Model serving logic
â”‚   â”œâ”€â”€ utils.py                     # Helper functions
â”‚   â”œâ”€â”€ types_.py                    # Type definitions
â”‚   â””â”€â”€ constants.py                 # Configuration
â”‚
â”œâ”€â”€ ğŸ“ mlruns/                        # MLflow tracking
â”‚   â”œâ”€â”€ 0/                           # Experiment runs
â”‚   â””â”€â”€ models/                      # Model registry
â”‚
â”œâ”€â”€ ğŸ“ nginx/                         # Load balancer config
â”‚   â”œâ”€â”€ Dockerfile                   
â”‚   â””â”€â”€ nginx.conf                   # Routing & balancing
â”‚
â”œâ”€â”€ ğŸ“ swarm/                         # Production deployment
â”‚   â”œâ”€â”€ app-compose.yml              # Application stack
â”‚   â””â”€â”€ model-compose.yml            # Model service stack
â”‚
â”œâ”€â”€ ğŸ“ demo/                          # Deployment utilities
â”‚   â”œâ”€â”€ init-swarm.sh                # Swarm initialization
â”‚   â”œâ”€â”€ init-compose.sh              # Compose setup
â”‚   â””â”€â”€ reload.py                    # Hot reload dev tool
â”‚
â”œâ”€â”€ ğŸ““ explore.ipynb                  # Data exploration
â”œâ”€â”€ ğŸ³ Dockerfile                     # Container definition
â”œâ”€â”€ ğŸ³ docker-compose.yml             # Local orchestration
â”œâ”€â”€ ğŸ“‹ requirements.txt               # Python dependencies
â””â”€â”€ ğŸ“‹ conda_environment.yml          # Conda environment
```

## ğŸš€ Getting Started

### Prerequisites

```bash
# Required
- Docker 20.10+
- Docker Compose 2.0+
- Python 3.12+

# Optional (for local development)
- Conda/Miniconda
- Jupyter Notebook
```

### Quick Start (Docker)

```bash
# 1. Clone the repository
git clone <your-repo-url>
cd house-price-prediction

# 2. Build and run with Docker Compose
docker-compose up --build

# 3. Access the application
# Web UI: http://localhost
# MLflow UI: http://localhost:5000
```

### Local Development Setup

```bash
# Option 1: Using pip
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Option 2: Using conda
conda env create -f conda_environment.yml
conda activate house-prediction

# Train model (if needed)
python model/create_model.py

# Explore data
jupyter notebook explore.ipynb

# Run application locally
python src/main.py
```

## ğŸ³ Production Deployment

### Docker Swarm (Recommended for Production)

```bash
# 1. Initialize Docker Swarm
docker swarm init

# 2. Deploy using the initialization script
cd demo
./init-swarm.sh

# 3. Or deploy manually
docker stack deploy -c swarm/app-compose.yml -c swarm/model-compose.yml housing-app

# 4. Scale services dynamically
docker service scale housing-app_model=5
docker service scale housing-app_web=3

# 5. Monitor services
docker service ls
docker service logs housing-app_model
```

### Deployment Features

- **Auto-scaling**: Services automatically recover from failures
- **Zero-downtime updates**: Rolling updates without service interruption
- **Load distribution**: Nginx distributes requests across healthy instances
- **Health checks**: Automatic unhealthy instance removal
- **Resource limits**: Configured memory and CPU constraints

## ğŸ§ª MLflow Experiment Tracking & Prefect Orchestration

### MLflow for Experiment Management

This project uses **MLflow** for comprehensive experiment tracking:

```bash
# Start MLflow UI
mlflow ui --backend-store-uri ./mlruns

# View experiments at http://localhost:5000
```

**Tracked Metrics:**
- Model performance (RMSE, MAE, RÂ²)
- Training hyperparameters
- Feature importance
- Model artifacts and versions

**Model Registry:**
- Version control for models
- Stage transitions (Staging â†’ Production)
- Model lineage and metadata

### Prefect for Workflow Orchestration

**Prefect** manages the end-to-end ML pipeline:

```bash
# Start Prefect server
prefect server start

# View Prefect UI at http://localhost:4200

# Run a workflow
python model/create_model.py
```

**Automated Workflows:**
- **Data Ingestion Flow**: Scheduled data updates and preprocessing
- **Training Pipeline**: Automated model retraining with new data
- **Deployment Flow**: Model validation and promotion to production
- **Monitoring Flow**: Performance tracking and alert notifications

**Key Features:**
- Task dependency management
- Automatic retries and error handling
- Scheduled and event-triggered runs
- Distributed execution capabilities
- Real-time monitoring dashboard

## ğŸ¯ Skills Demonstrated

### Machine Learning
- Feature engineering with domain knowledge
- Model selection and hyperparameter tuning
- Cross-validation and performance evaluation
- Handling real-world tabular data

### MLOps
- Experiment tracking with MLflow
- Workflow orchestration with Prefect
- Model versioning and registry management
- Reproducible training pipelines
- Model artifact management
- Automated retraining and deployment

### Software Engineering
- Type-safe Python with type hints
- Modular, maintainable code architecture
- Separation of concerns (MVC pattern)
- Configuration management

### DevOps & Infrastructure
- Containerization with Docker
- Microservices architecture
- Container orchestration (Docker Swarm)
- Load balancing and reverse proxy (Nginx)
- Service scaling and high availability
- Infrastructure as Code

### Data Engineering
- Data preprocessing and cleaning
- Feature engineering pipelines
- Data integration from multiple sources
- Schema management and validation

## ğŸ› ï¸ Technical Stack

| Category | Technologies |
|----------|-------------|
| **ML/Data** | Scikit-learn, Pandas, NumPy, MLflow |
| **Orchestration** | Prefect |
| **Backend** | Python 3.12, FastAPI/Flask |
| **Frontend** | HTML/CSS/JavaScript |
| **DevOps** | Docker, Docker Compose, Docker Swarm |
| **Infrastructure** | Nginx, Linux |
| **Development** | Jupyter, Git, VS Code |

## ğŸ§ª Testing

```bash
# Run unit tests
python -m pytest tests/

# Test model predictions
python model/evaluator.py

# Load test the API
# (Add your load testing commands)
```

## ğŸ”§ Configuration

Key configuration files:
- `requirements.txt` - Python dependencies
- `conda_environment.yml` - Conda environment
- `docker-compose.yml` - Local development setup
- `swarm/*.yml` - Production deployment configs
- `nginx/nginx.conf` - Load balancer configuration

## ğŸš§ Roadmap

- [x] Implement A/B testing framework
- [x] Add model monitoring and drift detection
- [ ] Add automated model retraining pipeline
- [ ] Add CI/CD pipeline (GitHub Actions)
- [ ] Create REST API documentation (OpenAPI/Swagger)
- [ ] Implement feature store
- [ ] Add comprehensive unit and integration tests

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- King County housing dataset
- MLflow for experiment tracking capabilities
- Prefect for workflow orchestration
- Docker community for containerization best practices

---

â­ **Star this repository if you found it helpful!**

*This project was created to demonstrate production ML engineering skills for portfolio purposes.*